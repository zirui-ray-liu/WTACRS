{
"do_train": true,
"do_eval": true,
"do_test": true,
"warmup_steps": 500,
"save_steps": 1000,
"model_name_or_path": "t5-3b",
"tokenizer_name": "t5-3b",
"save_total_limit": 1,
"per_device_train_batch_size": 32,
"per_device_eval_batch_size": 100,
"load_best_model_at_end": true,
"metric_for_best_model": "average_metrics",
"greater_is_better": true,
"evaluation_strategy": "epoch",
"non_linearity": "gelu_new",
"max_source_length": 128,
"task_name": "sst2",
"eval_dataset_name": "sst2",
"test_dataset_name": "sst2",
"num_train_epochs": 10,
"learning_rate": 0.0003,
"output_dir": "outputs/full_finetuning_sst2_t5-3b_LoRA_sd1",
"split_validation_test": false,
"dataset_config_name": [
"en"
],
"eval_dataset_config_name": [
"en"
],
"test_dataset_config_name": [
"en"
],
"overwrite_output_dir": true,
"predict_with_generate": true,
"bitfit": true,
"freeze_bitfit_lm_head": true,
"train_lora": true,
"compute_memory": true,
"compute_time": true,
"print_num_parameters": true,
"seed": 1,
"task_adapter_layers_encoder": null,
"trainable_encoder_layers": null,
"task_adapter_layers_decoder": null,
"trainable_decoder_layers": null,
"lora_dim": 32,
"pad_to_max_length": true
}